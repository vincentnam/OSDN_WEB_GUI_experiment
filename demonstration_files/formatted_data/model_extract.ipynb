{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing done.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Delete all variables\n",
    "%reset\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-11-22T12:38:39.825406828Z",
     "start_time": "2023-11-22T12:38:37.671428226Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "import json\n",
    "import os\n",
    "\n",
    "from lxml import etree\n",
    "import dateparser\n",
    "import re\n",
    "import datetime\n",
    "\n",
    "\n",
    "# TODO : Format date to interrop doc\n",
    "\n",
    "def get_all_keys(doc, main_key=None, separator=\".\", key_list = [], first_call=True):\n",
    "    '''\n",
    "    Get all key and sub key of a document, sub key are constructed with a separator defined as a parameter.\n",
    "    :param doc:\n",
    "    :param main_key:\n",
    "    :param separator:\n",
    "    :param first_call\n",
    "    :return:\n",
    "    '''\n",
    "    if isinstance(doc, type({})):\n",
    "\n",
    "        for key in  doc.keys():\n",
    "            if main_key is None :\n",
    "                key_list.append(key)\n",
    "                get_all_keys(doc[key],main_key=key, separator=separator, key_list=key_list, first_call=False)\n",
    "            else :\n",
    "                key_list.append(main_key+separator+key)\n",
    "                get_all_keys(doc[key],main_key=main_key+separator+key, separator=separator, key_list=key_list, first_call=False)\n",
    "    if isinstance(doc, type([])):\n",
    "        for obj in doc:\n",
    "            if isinstance(obj, type({})):\n",
    "                for key in  obj.keys():\n",
    "                    if main_key is None :\n",
    "                        key_list.append(key)\n",
    "                        get_all_keys(obj[key],main_key=key, separator=separator, key_list=key_list, first_call=False)\n",
    "                    else :\n",
    "                        key_list.append(main_key+separator+key)\n",
    "                        get_all_keys(obj[key],main_key=main_key+separator+key, separator=separator, key_list=key_list, first_call=False)\n",
    "\n",
    "    return key_list\n",
    "\n",
    "\n",
    "def remove_id_in_json(f_json):\n",
    "    \"\"\"\n",
    "    As mongoDB id or _id is reserved keyword, this function modify any field that is \"id\" or \"_id\" to add \"doc\" before.\n",
    "    :param f_json: dict containing a parsed json\n",
    "    :return: dict : f_json with a modified \"id\" or \"_id\" key if there was\n",
    "    \"\"\"\n",
    "    key_list = [\"id\",\"_id\"]\n",
    "    if index_key_list:=[index for index, key_is_present in enumerate([key in f_json for key in key_list ]) if key_is_present]:\n",
    "        for index in index_key_list :\n",
    "            f_json[\"doc_\"+ key_list[index]]= f_json.pop( key_list[index])\n",
    "    return f_json\n",
    "\n",
    "def format_date_json(doc):\n",
    "    if type(doc) is dict:\n",
    "        for key in doc.keys():\n",
    "            if (type(doc[key]) is str) and (date := dateparser.parse(doc[key])) is not None:\n",
    "                    doc[key]=date\n",
    "            format_date_json(doc[key])\n",
    "    if type(doc) is list:\n",
    "        for object in doc :\n",
    "            format_date_json(object)\n",
    "\n",
    "    return doc\n",
    "\n",
    "\n",
    "def read_preprocess_insert_in_mongodb_json(fp, mongodb_coll=None, fp_is_dict=False):\n",
    "    \"\"\"\n",
    "    Read, remove any incompatible \"id\" key and insert the JSON in a collection in a mongodb database\n",
    "    :param fp: str : file_path to a JSON to read\n",
    "    :param mongodb_coll: MongoClient.database.collection : A collection in which insert files\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    if mongodb_coll is None:\n",
    "        mongodb_coll = MongoClient(\"localhost:27017\").no_model_name.interop_metadata\n",
    "        print(\"coucou\")\n",
    "    try:\n",
    "        # mongodb_coll.insert_one(format_date_json(remove_id_in_json(json.load(open(fp)))))\n",
    "        # Error seens in data formatting\n",
    "        if fp_is_dict:\n",
    "            mongodb_coll.insert_one((remove_id_in_json(fp)))\n",
    "        else:\n",
    "            mongodb_coll.insert_one((remove_id_in_json(json.load(open(fp)))))\n",
    "        # print(fp + \" has been inserted successfully.\")\n",
    "    except Exception as exce :\n",
    "        print(\"Insertion has not been successfully done. Logs : \" + str(exce))\n",
    "\n",
    "def dont_contains_dict(liste):\n",
    "    for elem in liste :\n",
    "        # print(elem)\n",
    "        if type(elem) is dict:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "# Transform a date to standard format\n",
    "def format_date(date):\n",
    "    # Transform a string date into a standard format by trying each\n",
    "    # date format. If you want to add a format, add a try/except in the\n",
    "    # last except\n",
    "    # date : str : the date to transform\n",
    "    # return : m : timedata : format is YYYY-MM-DD HH:MM:SS\n",
    "    date_str = date\n",
    "    #\n",
    "    date_str = date_str.replace(\"st\",\"\").replace(\"th\",\"\")\\\n",
    "        .replace(\"nd\",\"\").replace(\"rd\",\"\").replace(\" Augu \",\" Aug \")\n",
    "    m = None\n",
    "    sep_list = [\".\",\"/\",\"-\",\"_\",\" \",\":\"]\n",
    "    for date_sep in sep_list:\n",
    "        try:\n",
    "            m = datetime.datetime.strptime(date_str, \"%d\"+date_sep+\"%B\"+date_sep+\"%Y\")\n",
    "            break\n",
    "        except ValueError:\n",
    "            try:\n",
    "                m = datetime.datetime.strptime(date_str, \"%d\"+date_sep+\"%b\"+date_sep+\"%Y\")\n",
    "                break\n",
    "            except ValueError:\n",
    "                try:\n",
    "                    m = datetime.datetime.strptime(date_str, \"%Y\"+date_sep+\"%m\"+date_sep+\"%d\")\n",
    "                    break\n",
    "                except ValueError:\n",
    "                    try :\n",
    "                        m = datetime.datetime.strptime(date_str,\n",
    "                                                   \"%d\"+date_sep+\"%m\"+date_sep+\"%Y\")\n",
    "                        break\n",
    "                    except ValueError:\n",
    "                        for hour_sep in sep_list:\n",
    "                            try:\n",
    "                                m = datetime.datetime\\\n",
    "                                    .strptime(date_str,\"%d\"+date_sep+\"%m\"+date_sep+\"%Y %H\"+hour_sep+\"%M\"+hour_sep+\"%S\")\n",
    "                                break\n",
    "                            except ValueError:\n",
    "                                try:\n",
    "                                    m = datetime.datetime\\\n",
    "                                        .strptime(date_str, \"%Y\"+date_sep+\"%m\"+date_sep+\"%d %H\"+hour_sep+\"%M\"+hour_sep+\"%S\")\n",
    "                                    break\n",
    "                                except ValueError:\n",
    "                                    # HERE ADD A FORMAT TO CHECK\n",
    "                                    # print(\"Format not recognised. \\nConsider \"\n",
    "                                    #       \"adding a date format \"\n",
    "                                    #       \"in the function \\\"format_date\\\".\")\n",
    "                                    pass\n",
    "\n",
    "    return m\n",
    "\n",
    "def XML_to_dict(xml):\n",
    "    xml_tag = re.sub(\"{.*}\",\"\",xml.tag)\n",
    "    res_dict ={xml_tag:{}}\n",
    "    path = [xml_tag]\n",
    "    def tree_walk(xml, path):\n",
    "        aux_path = path\n",
    "        for child in xml.getchildren():\n",
    "            child_tag=re.sub(\"{.*}\",\"\",child.tag)\n",
    "            aux = res_dict\n",
    "            for i in path:\n",
    "                aux = aux[i]\n",
    "            if child_tag in aux:\n",
    "                for attr in child.attrib:\n",
    "\n",
    "                    if re.sub(\"{.*}\",\"\",attr) in aux[child_tag]:\n",
    "\n",
    "                        if isinstance(aux[child_tag][re.sub(\"{.*}\",\"\",attr)], list):\n",
    "                            aux[child_tag][re.sub(\"{.*}\",\"\",attr)].append(child.attrib[attr])\n",
    "                        else :\n",
    "                            aux[child_tag][re.sub(\"{.*}\",\"\",attr)] = [aux[child_tag][re.sub(\"{.*}\",\"\",attr)]] + [child.attrib[attr]]\n",
    "                    else :\n",
    "                        aux[child_tag][re.sub(\"{.*}\",\"\",attr)] = child.attrib[attr]\n",
    "                if isinstance(child.text,str):\n",
    "                    if child.text.strip():\n",
    "                        if \"@value\" in aux[child_tag]:\n",
    "                            if isinstance(aux[child_tag][\"@value\"],list):\n",
    "\n",
    "                                        aux[child_tag][\"@value\"].append(child.text)\n",
    "                            else:\n",
    "                                aux[child_tag][\"@value\"]=[aux[child_tag][\"@value\"]]+[child.text]\n",
    "                        else:\n",
    "                            aux[child_tag][\"@value\"]=child.text\n",
    "            else:\n",
    "                aux[child_tag]={}\n",
    "                for attr in child.attrib:\n",
    "                    aux[child_tag][re.sub(\"{.*}\",\"\",attr)]=child.attrib[attr]\n",
    "                if isinstance(child.text,str):\n",
    "                    if child.text.strip():\n",
    "                        aux[child_tag][\"@value\"]=child.text\n",
    "            tree_walk(child, aux_path+[child_tag])\n",
    "    for child in xml.getchildren():\n",
    "        child_tag=re.sub(\"{.*}\",\"\",child.tag)\n",
    "        if child_tag in res_dict[xml_tag]:\n",
    "            for attr in child.attrib:\n",
    "                if re.sub(\"{.*}\",\"\",attr) in res_dict[xml_tag][child_tag]:\n",
    "                    if isinstance(res_dict[xml_tag][child_tag][re.sub(\"{.*}\",\"\",attr)], list):\n",
    "                        res_dict[xml_tag][child_tag][re.sub(\"{.*}\",\"\",attr)].append(child.attrib[attr])\n",
    "                    else:\n",
    "                        res_dict[xml_tag][child_tag][re.sub(\"{.*}\",\"\",attr)] = [res_dict[xml_tag][child_tag][re.sub(\"{.*}\",\"\",attr)]] + [child.attrib[attr]]\n",
    "                else:\n",
    "                    res_dict[xml_tag][child_tag][re.sub(\"{.*}\",\"\",attr)]=child.attrib[attr]\n",
    "            if isinstance(child.text,str):\n",
    "                if child.text.strip():\n",
    "                    if \"@value\" in res_dict[xml_tag][child_tag]:\n",
    "                        if isinstance(res_dict[xml_tag][child_tag][\"@value\"],list):\n",
    "                                    res_dict[xml_tag][child_tag][\"@value\"].append(child.text)\n",
    "                        else:\n",
    "                            res_dict[xml_tag][child_tag][\"@value\"]=[res_dict[xml_tag][child_tag][\"@value\"]]+[child.text]\n",
    "                    else:\n",
    "                        res_dict[xml_tag][child_tag][\"@value\"]=child.text\n",
    "        else:\n",
    "            res_dict[xml_tag][child_tag]={}\n",
    "            for attr in child.attrib:\n",
    "                res_dict[xml_tag][child_tag][re.sub(\"{.*}\",\"\",attr)]=child.attrib[attr]\n",
    "            if isinstance(child.text,str):\n",
    "                if child.text.strip():\n",
    "                    if \"@value\" in res_dict[xml_tag][child_tag]:\n",
    "                        if isinstance(res_dict[xml_tag][child_tag][\"@value\"],list):\n",
    "                            res_dict[xml_tag][child_tag][\"@value\"].append(child.text.strip())\n",
    "                        else:\n",
    "                            res_dict[xml_tag][child_tag][\"@value\"]=res_dict[xml_tag][child_tag][\"@value\"]+[child.text]\n",
    "\n",
    "                    else:\n",
    "                        res_dict[xml_tag][child_tag][\"@value\"]=child.text\n",
    "        tree_walk(child, path+[child_tag])\n",
    "    return res_dict\n",
    "\n",
    "\n",
    "def from_keyset_to_csv(key_set, separator=\".\"):\n",
    "    color = {\"0\":\"#F3722C\",\"1\":\"#F8961E\",\"2\":\"#F9C74F\",\"3\":\"#90BE6D\", \"4\":\"#43AA8B\",\"5\":\"#4D908E\",\"6\":\"#577590\",\"7\":\"#277DA1\", \"8\":\"#bdd5ea\", \"9\":\"#e3e2e3\",\"10\":\"#ffffff\", \"11\":\"#ffffff\"}\n",
    "    csv_list = [(\"ROOT_NODE\",\"\",-1,\"#F94144\")]\n",
    "    for key_concat in key_set:\n",
    "        key_split = key_concat.split(separator)\n",
    "        for index in range(len(key_split)):\n",
    "            if index <9:\n",
    "                if len(key_split)==1:\n",
    "                    csv_list.append((separator.join(key_split[:index+1]),\"ROOT_NODE\", index, color[str(index)]))\n",
    "                    break\n",
    "                if index == len(key_split) -1:\n",
    "                    break\n",
    "                csv_list.append((separator.join(key_split[:index+2]),separator.join(key_split[:index+1]),index+1, color[str(index+1)]))\n",
    "\n",
    "            else :\n",
    "                if index == len(key_split) -1:\n",
    "                    break\n",
    "                csv_list.append((separator.join(key_split[:index+2]),separator.join(key_split[:index+1]),index+1,\"#ffffff\"))\n",
    "    return ([\"key\",\"mother_key\", \"level\",\"color\"],set(csv_list))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-02-06T15:15:30.214833908Z",
     "start_time": "2024-02-06T15:15:30.173687890Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-02-06T15:15:31.020872555Z",
     "start_time": "2024-02-06T15:15:31.016433052Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Run a MongoDB database on localhost on port 27017 before running this cell"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['opendatasoft', 'AERIS', 'theia', 'formater', 'data-Europa-eu', 'ncbi-nlm-nih', 'figshare', 'humdata-org', 'bv-brc', 'harvard_dataverse', 'emdb']\n",
      "../raw_data/opendatasoft/datasets.csv\n",
      "../raw_data/ncbi-nlm-nih/csv-trichoderm-set.csv\n",
      "../raw_data/bv-brc/BVBRC_experiment.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "mongo_client = MongoClient(\"localhost:27017\")\n",
    "base_path=\"../raw_data/\"\n",
    "model_dict={}\n",
    "model_examples_folder = list(os.walk(base_path))[0][1]\n",
    "print(model_examples_folder)\n",
    "for model_name in model_examples_folder:\n",
    "    # print(model_name)\n",
    "    file_list=[]\n",
    "    mongodb_coll_var = mongo_client[model_name].interop_metadata\n",
    "    # print(model_name)\n",
    "    for i in os.walk(base_path+model_name):\n",
    "        # print(i)\n",
    "        for j in i[2]:\n",
    "            # print(j)\n",
    "            if j.endswith(\".json\"):\n",
    "                file_path=os.path.join(i[0],j)\n",
    "                file_list.append((os.path.join(i[0],j),model_name,\"json\"))\n",
    "                read_preprocess_insert_in_mongodb_json(file_path, mongodb_coll=mongodb_coll_var)\n",
    "                # print(file_path)\n",
    "            if j.endswith(\".xml\"):\n",
    "                try:\n",
    "                    file_list.append((os.path.join(i[0],j),model_name,\"xml\"))\n",
    "                    file = etree.parse(open(os.path.join(i[0],j)), parser=etree.XMLParser(ns_clean=True, remove_comments=True, recover=True)).getroot()\n",
    "                    res = XML_to_dict(file)\n",
    "                    read_preprocess_insert_in_mongodb_json(res, mongodb_coll=mongodb_coll_var, fp_is_dict=True)\n",
    "                except Exception as e:\n",
    "                    print(os.path.join(i[0],j))\n",
    "                    print(e)\n",
    "            if j.endswith(\".csv\"):\n",
    "                print((os.path.join(i[0],j)))\n",
    "                if os.path.join(i[0],j) == \"../raw_data/opendatasoft/datasets.csv\":\n",
    "                    csv_data = pd.read_csv(os.path.join(i[0],j), sep=\";\", nrows=100)\n",
    "                    csv_data.columns = csv_data.columns.map(lambda x : x.replace(\".\",\"_\"))\n",
    "                    # print(get_delimiter(\"../raw_data/opendatasoft/datasets.csv\"))\n",
    "                    json_data = csv_data.to_json(orient='records')\n",
    "                    # print(type(json.loads(json_data)))\n",
    "                    for document in json.loads(json_data):                \n",
    "                        read_preprocess_insert_in_mongodb_json(document, mongodb_coll=mongodb_coll_var, fp_is_dict=True)\n",
    "                else:\n",
    "                    csv_data = pd.read_csv(os.path.join(i[0],j), sep=\",\", nrows=100)\n",
    "                    # print(get_delimiter(\"../raw_data/opendatasoft/datasets.csv\"))\n",
    "                    json_data = csv_data.to_json(orient='records')\n",
    "                    # print(type(json.loads(json_data)))\n",
    "                    for document in json.loads(json_data):                \n",
    "                        read_preprocess_insert_in_mongodb_json(document, mongodb_coll=mongodb_coll_var, fp_is_dict=True)\n",
    " \n",
    "    model_dict[model_name]=file_list\n",
    "\n",
    "# print(model_dict)\n",
    "\n",
    "# pd.DataFrame(model_dict[\"FHIR\"],columns=[\"Filepath\",\"Model\",\"File extension\"])\n",
    "\n",
    "# model_dict\n",
    "for model_name in model_dict:\n",
    "    mongodb_coll_var = mongo_client[model_name].interop_metadata\n",
    "    model_key_set=[]\n",
    "    model_key_set=set(model_key_set)\n",
    "    docs=mongodb_coll_var.find()\n",
    "    for doc in docs:\n",
    "        model_key_set = model_key_set.union(set(get_all_keys(doc, separator=\".\", key_list=[])))\n",
    "    distinct_keys = {}\n",
    "    for key in model_key_set:\n",
    "        if key != \"_id\":\n",
    "            value_filled=False\n",
    "            value = mongodb_coll_var.distinct(key)\n",
    "            for obj in value:\n",
    "                if isinstance(obj, type({})):\n",
    "\n",
    "                    value_filled = True\n",
    "                    break\n",
    "            if not value_filled:\n",
    "                distinct_keys[key.replace(\"#\",\".\")]={\n",
    "                    \"count\":mongodb_coll_var.count_documents({key:{\"$exists\":True}}),\n",
    "                    \"values\": value\n",
    "                }\n",
    "    pd.DataFrame(distinct_keys).transpose().to_csv(model_name+\"_model.csv\", index_label=\"concept\")\n",
    "    # pd.DataFrame(distinct_keys).transpose().to_csv(model_name+\"_model.csv\", index_label=\"concept\")\n",
    "    \n",
    "    # break\n",
    "# files = list(os.walk(\"./examples/\"))[0][2]\n",
    "# files"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-02-06T15:15:33.355776046Z",
     "start_time": "2024-02-06T15:15:31.985918179Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
